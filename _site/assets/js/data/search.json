[
  
  {
    "title": "Big O Notation",
    "url": "/posts/BigO/",
    "categories": "Programming, Algorithm",
    "tags": "algorithm, programming, math, c++",
    "date": "2024-02-09 00:23:00 +0900",
    





    
    "snippet": "In this post, we’ll explore the concept of Big O notation, common time complexities, and visualize how these complexities grow as the input size increases.IntroductionTime and Space ComplexityAlgor...",
    "content": "In this post, we’ll explore the concept of Big O notation, common time complexities, and visualize how these complexities grow as the input size increases.IntroductionTime and Space ComplexityAlgorithms are crucial part of any program, and good a programmer chooses the most efficient algorithm to solve a problem.To analyze the efficiency of an algorithm, there are two big considerations:      Time Complexity - a measure of the amount of time an algorithm takes to run, in relation to the size of the input data.        Sapce Complexity - a measure of the amount of computer memory (or space) an algorithm needs to run to completion.  Why do algorithms matter?ExampleConsider a simple problem: calculating the sum of all numbers up to an integer n.\\[\\sum_{i=1}^{n} i = \\frac{n(n + 1)}{2}\\]Solution 1: Efficient Algorithmdef sum(n):    return (n * (n+1)) / 2Solution 2: Inefficient Algorithmdef sum(n):    sum = 0    for i in range(1, n+1):        sum += i    return sumThe first solution does not take any memory space as there is no variable assignment involved in the solution.Also, regardless of how large the input n is, the code will just execute a simple mathematical expression.On the other hand, the second solution requires a memory space to save the variable sum, and it executes the addition inside the for loop n times.The difference between the performances of the two solutions might be subtle when n is small, yet as n becomes larger, the difference will grow and be noticeable.Choosing a good algorithm is a must to optimize the performance and efficiency of a program.In the real world, poor efficiency will result in taking up more resources, and thus, more cost.Big O Notation enables programmers to analyze the complexity and the efficiency of an algorithm.DefinitionBig O notation is a mathematical notation that describes the limiting behavior of a function when the argument tends towards a particular value or infinity. In computer science, it is used to analyze the efficiency of algorithms and estimate their worst-case time complexity.Formal DefinitionLet $f(n)$ and $g(n)$ be functions mapping positive integers to positive real numbers. We say that $f(n)$ is $O(g(n))$, read as “f of n is big O of g of n”, if and only if there exist positive constants $c$ and $n_0$ such that:for all $n \\geq n_0$, \\(f(n) \\leq c \\cdot g(n)\\)This means that $f(n) = O(g(n))$ indicates that the growth rate of $f(n)$ is bounded above by the growth rate of $g(n)$ up to a constant factor, for sufficiently large $n$. This notation is used to classify algorithms according to their running time or space requirements in the worst-case scenario.Common Time ComplexitiesCommon Time Complexities include the following:  Constant time  Linear time  Logarithmic time  Linearithmic time  Quadratic time  Exponential time$O({1})$ - Constant Time$O({1})$ represents algorithms that always execute in the same time (or space) regardless of the size of the input data.Example: Accessing a specific element in an array.#include &lt;iostream&gt;int main(){    int myArray[] = {1, 2, 3, 4, 5};    std::cout &lt;&lt; myArray[0]; // returns the first element regardless of the size of the array    return 0;}$O(n)$ - Linear Time$O(n)$ represents algorithms whose performance grows linearly and in direct proportion to the size of the input data set.Example: Traversing an array.#include&lt;iostream&gt;int main(){    int myArray[] = {1, 2, 3, 4, 5};    for(int i = 0; i &lt; 5; i++) {        std::cout &lt;&lt; myArray[i]; // prints each element in the array    }    return 0;}$O(\\log n)$ - Logarithmic TimeLogarithmic time complexity $O(\\log n)$ describes an algorithm that reduces the size of its input data by a significant fraction (usually half) with each step, leading to fewer steps as the input size grows.Example: Binary search in a sorted array.#include &lt;bits/stdc++.h&gt;using namespace std;int binarySearch(int arr[], int l, int r, int x){    while (l &lt;= r) {        int m = l + (r - l) / 2;        if (arr[m] == x)            return m;        if (arr[m] &lt; x)            l = m + 1;        else            r = m - 1;    }    return -1;}int main(void){    int arr[] = { 2, 3, 4, 10, 40 };    int x = 10;    int n = sizeof(arr) / sizeof(arr[0]);    int result = binarySearch(arr, 0, n - 1, x);    (result == -1)        ? cout &lt;&lt; \"Element is not present in array\"        : cout &lt;&lt; \"Element is present at index \" &lt;&lt; result;    return 0;}$O(n\\log n)$ - Linearithmic TimeLinearithmic time complexity $O(n\\log n)$ represents algorithms where the time grows in proportion to $n \\log n$, combining linear and logarithmic behavior. This complexity is common in efficient sorting algorithms.Example: Merge Sort algorithm.#include &lt;bits/stdc++.h&gt;using namespace std;void merge(int array[], int const left, int const mid,\t\tint const right){\tint const subArrayOne = mid - left + 1;\tint const subArrayTwo = right - mid;\tauto *leftArray = new int[subArrayOne],\t\t*rightArray = new int[subArrayTwo];\tfor (auto i = 0; i &lt; subArrayOne; i++)\t\tleftArray[i] = array[left + i];\tfor (auto j = 0; j &lt; subArrayTwo; j++)\t\trightArray[j] = array[mid + 1 + j];\tauto indexOfSubArrayOne = 0, indexOfSubArrayTwo = 0;\tint indexOfMergedArray = left;\twhile (indexOfSubArrayOne &lt; subArrayOne\t\t&amp;&amp; indexOfSubArrayTwo &lt; subArrayTwo) {\t\tif (leftArray[indexOfSubArrayOne]\t\t\t&lt;= rightArray[indexOfSubArrayTwo]) {\t\t\tarray[indexOfMergedArray]\t\t\t\t= leftArray[indexOfSubArrayOne];\t\t\tindexOfSubArrayOne++;\t\t}\t\telse {\t\t\tarray[indexOfMergedArray]\t\t\t\t= rightArray[indexOfSubArrayTwo];\t\t\tindexOfSubArrayTwo++;\t\t}\t\tindexOfMergedArray++;\t}\twhile (indexOfSubArrayOne &lt; subArrayOne) {\t\tarray[indexOfMergedArray]\t\t\t= leftArray[indexOfSubArrayOne];\t\tindexOfSubArrayOne++;\t\tindexOfMergedArray++;\t}\twhile (indexOfSubArrayTwo &lt; subArrayTwo) {\t\tarray[indexOfMergedArray]\t\t\t= rightArray[indexOfSubArrayTwo];\t\tindexOfSubArrayTwo++;\t\tindexOfMergedArray++;\t}\tdelete[] leftArray;\tdelete[] rightArray;}void mergeSort(int array[], int const begin, int const end){\tif (begin &gt;= end)\t\treturn;\tint mid = begin + (end - begin) / 2;\tmergeSort(array, begin, mid);\tmergeSort(array, mid + 1, end);\tmerge(array, begin, mid, end);}void printArray(int A[], int size){\tfor (int i = 0; i &lt; size; i++)\t\tcout &lt;&lt; A[i] &lt;&lt; \" \";\tcout &lt;&lt; endl;}int main(){\tint arr[] = { 12, 11, 13, 5, 6, 7 };\tint arr_size = sizeof(arr) / sizeof(arr[0]);\tcout &lt;&lt; \"Given array is \\n\";\tprintArray(arr, arr_size);\tmergeSort(arr, 0, arr_size - 1);\tcout &lt;&lt; \"\\nSorted array is \\n\";\tprintArray(arr, arr_size);\treturn 0;}$O(n^2)$ - Quadratic TimeQuadratic time complexity $O(n^2)$ indicates that the time taken by an algorithm is proportional to the square of the input size. It is common in algorithms that perform nested iterations over the data set.Example: Bubble sort algorithm.#include &lt;bits/stdc++.h&gt;using namespace std;void bubbleSort(int arr[], int n){\tint i, j;\tbool swapped;\tfor (i = 0; i &lt; n - 1; i++) {\t\tswapped = false;\t\tfor (j = 0; j &lt; n - i - 1; j++) {\t\t\tif (arr[j] &gt; arr[j + 1]) {\t\t\t\tswap(arr[j], arr[j + 1]);\t\t\t\tswapped = true;\t\t\t}\t\t}\t\tif (swapped == false)\t\t\tbreak;\t}}void printArray(int arr[], int size){\tint i;\tfor (i = 0; i &lt; size; i++)\t\tcout &lt;&lt; \" \" &lt;&lt; arr[i];}int main(){\tint arr[] = { 64, 34, 25, 12, 22, 11, 90 };\tint N = sizeof(arr) / sizeof(arr[0]);\tbubbleSort(arr, N);\tcout &lt;&lt; \"Sorted array: \\n\";\tprintArray(arr, N);\treturn 0;}$O(2^n)$ - Exponential TimeExponential time complexity $O(2^n)$ describes an algorithm whose growth doubles with each addition to the input data set. This complexity is typical in brute-force algorithms for solving complex problems.Example: Fibonacci sequence using recursion.#include &lt;iostream&gt;int fibonacci(int n) {    if (n &lt;= 1)        return n;    return fibonacci(n - 1) + fibonacci(n - 2);}int main() {    int n = 10;    std::cout &lt;&lt; \"Fibonacci number is \" &lt;&lt; fibonacci(n);    return 0;}* The detailed observation into the algorithms introduced in this part will be posted laterVisualization of the Time Complexitiesimport matplotlib.pyplot as pltimport numpy as npn = np.arange(1, 100)plt.figure(figsize=(10, 6))# O(1)plt.plot(n, np.ones_like(n), label='$O(1)$', linestyle='--')# O(n)plt.plot(n, n, label='$O(n)$')# O(log n)plt.plot(n, np.log(n), label='$O(\\log n)$')# O(n log n)plt.plot(n, n*np.log(n), label='$O(n \\log n)$')# O(n^2)plt.plot(n, n**2, label='$O(n^2)$')# O(2^n)plt.plot(n, 2**n, label='$O(2^n)$')plt.title('Common Time Complexities')plt.xlabel('Input Size (n)')plt.ylabel('Operations')plt.grid(True)plt.legend()plt.yscale('log')plt.ylim(0, 10000)plt.show()ConclusionAnalyzing the efficiency of an algorithm is a necessary process for making informed decisions when designing a program. Big O notation is a useful strategy for investigating the time and space complexity of an algorithm, and thus, understanding Big O notation is crucial for developers and programmers to optimize the performance of their programs.References      Modeling Social Data. (2017, February 3). Lecture 3: Computational Complexity. Retrieved February 9, 2024, from http://modelingsocialdata.org/lectures/2017/02/03/lecture-3-computational-complexity.html        GeeksforGeeks. (n.d.). Binary Search. Retrieved February 9, 2024, from https://www.geeksforgeeks.org/binary-search/        GeeksforGeeks. (n.d.). Merge Sort. Retrieved February 9, 2024, from https://www.geeksforgeeks.org/merge-sort/        GeeksforGeeks. (n.d.). Bubble Sort. Retrieved February 9, 2024, from https://www.geeksforgeeks.org/bubble-sort/  "
  },
  
  {
    "title": "Python Tutorial - Chapter 1",
    "url": "/posts/Chapter1/",
    "categories": "Python Tutorials",
    "tags": "python",
    "date": "2024-02-08 13:23:00 +0900",
    





    
    "snippet": "Welcome to Python Tutorial!There are many Human Languages, such as English, Korean, Spanish, Chinese, etc.Just Like humans, computers also have different languages for communication, such as C/C++,...",
    "content": "Welcome to Python Tutorial!There are many Human Languages, such as English, Korean, Spanish, Chinese, etc.Just Like humans, computers also have different languages for communication, such as C/C++, Assembly, Java, JavaScript, and Python.Why Python?Interpreter V.S. CompilerComputers fundamentally only understand languages written with 0 and 1, often referred to as “Machine Language”. No matter what language programmers code in, there must be a process of converting that into machine language. This conversion is done by either an interpreter or a compiler.Two popular examples of these types of languages are C (a compiled language) and Python (an interpreted language). Compiled languages like C usually perform faster, but they can be more difficult to code and debug.Python, on the other hand, is an interpreted language. This means that it is relatively easy to write and fix errors in Python. The interpreter executes the code line by line, which allows for more immediate feedback and easier debugging. This is one of the reasons why Python is popular for beginners and for rapid development.Easy to LearnPython is easy to learn for several reasons.      Readability: Python’s syntax is designed to be readable and straightforward. This makes it easier for beginners to pick up the language and understand what the code is doing.        High-level language: Python is a high-level language, meaning it abstracts many of the complex details of the computer. This allows beginners to start coding without needing to understand complex computer science concepts.        Large Standard Library: Python comes with a large standard library that covers many areas, from web development to machine learning. This means beginners can do a lot with Python without needing to understand or use external libraries.        Strong Community: Python is an open source and has a large and supportive community. This means there are plenty of resources available for learning and troubleshooting, from online tutorials to forums and Q&amp;A websites.  For example, these are the codes for printing “Hello World!” in three different languages.C++#include &lt;iostream&gt;using namespace std;int main() {    cout &lt;&lt; \"Hello World!\";    return 0;}Javapublic class HelloWorld {    public static void main(String[] args) {        System.out.println(\"Hello World!\");    }}Pythonprint(\"Hello World!\")Wide UsecasesPython has gained its popularity because of its wide range of domains.Python is useful for these tasks:  Web development  Data Science / Data Analysis  Machine Learning  Artificial IntelligencePopular programs developed with Python:  YouTube  Google  Instagram  Spotify  AmazonInstallationWe will be using Jupyter Notebook for this tutorial.What is a Jupyter Notebook?Jupyter Notebook is an interactive web application for creating and sharing computational documents.It is useful to write and run Python codes on a web environment without sophisticated setup process.Install AnacondaTo setup the device, please visit the website andInstall Anaconda.Anaconda is a useful tool that automatically install all the softwares required for writing Python code in Jupyter Notebook.Launch Jupyter NotebookAfter the installation is completed, open the Anaconda panel and find Jupyter Notebook to launch the program.Choose DirectoryGo to the directory where you want to store the tutorial materials.Click new button on the top right corner, and choose Python 3 kernal.Writing the first codeNow, let’s write our first Python code.In the first code cell, type the following codeprint(\"Hello, Python!\")and press shift + enter to run the code.Hello, Python!If you see the text printed, the software is successfully installed.“The only way to learn a new programming language is by writing programs in it.”- Dennis Ritchie"
  },
  
  {
    "title": "Recursion",
    "url": "/posts/Recursion/",
    "categories": "Programming, Algorithm",
    "tags": "algorithm, programming, python",
    "date": "2024-02-08 00:23:00 +0900",
    





    
    "snippet": "Recursion in algorithms is a method where a problem is solved by breaking it down into smaller instances of the same problem. This approach involves a function calling itself with a smaller input u...",
    "content": "Recursion in algorithms is a method where a problem is solved by breaking it down into smaller instances of the same problem. This approach involves a function calling itself with a smaller input until it reaches a condition known as the base case, which is simple enough to be solved directly. Once the base case is reached, the solution to that base case is used to solve the other instances of the problem, building up to the solution of the original problem.  The base case is the condition to stop the recursion  The recursive case is the part where the function calls on itself.print 1 to 10 using recursive functionwithout recursion, the code would look like this:for i in range(11):    print(i)012345678910same task done with recursion:def printNum(n = 1):    if n &gt; 10: #This is a base case        return    else: # This is a recursive case        print(n)        printNum(n + 1)printNum()12345678910Factorialfactorial is a function that multiplies a number by every number below it till 1without recursion:n = 6num = 1for i in range(n):    num *= n    n -= 1print(num)720with recursion:def Factorial(n):    num = 1    if n &lt; 0: # This is a Boundary Case        raise ValueError(\"The input must be a non-negative integer\")    elif n &lt;= 1: # This is a base case        return 1    else: # This is a recursive case        return n * Factorial(n - 1)print(Factorial(6))720FibonacciFibonacci sequence is a sequence in which each number is the sum of the two preceding ones.without recursion:n = 6a_1 = 0a_2 = 1for i in range(n - 1):    a_1, a_2 = a_2, a_1 + a_2print(a_2)8def Fibonacci(n):    if n == 0: # This is a base case        return 0    elif n == 1: # This is another base case        return 1    elif n &gt; 1: # This is a recursive case        return Fibonacci(n - 1) + Fibonacci(n - 2)    else: # This is a boundary case        raise ValueError(\"Negative integer is invalid\")print(Fibonacci(6))“To understand recursion, one must first understand recursion.”-Stephen Hawking-"
  }
  
]

